{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do you know your stroke risk?\n",
    "\n",
    "Source of the data: https://www.sciencedirect.com/science/article/pii/S0933365719302295?via%3Dihub\n",
    "Liu, Tianyu; Fan, Wenhui; Wu, Cheng (2019), “Data for: A hybrid machine learning approach to cerebral stroke prediction based on imbalanced medical-datasets”, Mendeley Data, V1, doi: 10.17632/x8ygrw87jw.1\n",
    "\n",
    "The medical dataset contains 43,400 records of potential patients which includes 783 occurrences of stroke. \n",
    "\n",
    "Cerebral stroke has become a significant global public health issue. The ideal solution to this concern is to prevent in advance by controlling related metabolic factors. However, it is difficult for medical staff to decide whether special precautions are needed for a potential patient only based on the monitoring of physiological indicators unless they are obviously abnormal. This project builds a machine learning model to predict whether someone is at risk of having a stroke.\n",
    "\n",
    "The data in each row includes numerical factors, such as age and average glucose levels, and categorical factors, such as \"has heart disease\" (yes or no), work type, and smoking status. This is not an exhaustive list. We use this data to determine which factors contribute to having a stroke, and among those which hold the most weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic analysis of the input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43400, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as sts\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "#sns.set_style('whitegrid')\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "#tensorflow.keras.__version__\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from joblib import dump, load\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import imblearn\n",
    "print(imblearn.__version__)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Read the golf course dataset\n",
    "input_csv = pd.read_csv(\"data/stroke_dataset.csv\", delimiter=',', skipinitialspace=True)\n",
    "input_csv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Code Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_net(X,y, filename):\n",
    "    dim = X.shape[1]\n",
    "    \n",
    "\n",
    "    \n",
    "    print(\"**********************\")\n",
    "    print(f\"Before X: {X.shape}\")\n",
    "    print(f\"Before y: {y.shape}\")\n",
    "    \n",
    "    sm = SMOTE()\n",
    "    X, y = sm.fit_resample(X,y)\n",
    "      \n",
    "    print(\"**********************\")\n",
    "    print(f\"SMOTED X: {X.shape}\")\n",
    "    print(f\"SMOTED y: {y.shape}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 50)\n",
    "    \n",
    "    X_scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    # Step 1: Label-encode data set\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(y_train)\n",
    "    encoded_y_train = label_encoder.transform(y_train)\n",
    "    encoded_y_test = label_encoder.transform(y_test)\n",
    "    # Step 2: Convert encoded labels to one-hot-encoding\n",
    "    y_train_categorical = to_categorical(encoded_y_train)\n",
    "    y_test_categorical = to_categorical(encoded_y_test)\n",
    "    \n",
    "    print(f\"X_scaler: {X_scaler}\")\n",
    "    \n",
    "    dump(X_scaler, 'NN_minmaxscaler.bin', compress = True)\n",
    "    unit_num = 55\n",
    "    \n",
    "    # Create model and add layers\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=unit_num, activation='relu', input_dim=dim))\n",
    "    model.add(Dense(units=unit_num, activation='relu'))\n",
    "    model.add(Dense(units=unit_num, activation='relu'))\n",
    "    model.add(Dense(units=unit_num, activation='relu'))\n",
    "    model.add(Dense(units=unit_num, activation='relu'))\n",
    "    \n",
    "    \n",
    "#   model.add(Dense(units=unit_num, activation='relu'))    \n",
    " #    model.add(Dense(units=unit_num), activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    #categorical_crossentropy\n",
    "    \n",
    "    # Compile and fit the model\n",
    "    model.compile(optimizer='Adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[tf.keras.metrics.PrecisionAtRecall(recall = 0.85)])\n",
    "    \n",
    "    model.summary()\n",
    "    model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    "    )\n",
    "    model_result = model.evaluate(\n",
    "        X_test_scaled, y_test_categorical, verbose=2)\n",
    "    \n",
    "    print(\"/n\")\n",
    "    print(\"Test Results\")\n",
    "    print(f\"Normal Neural Network - Loss: {model_result[0]}, Accuracy: {model_result[1]}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    uniqueValues_train, occurCount_train = np.unique(y_train, return_counts=True)\n",
    "    uniqueValues_test, occurCount_test = np.unique(y_test, return_counts=True)\n",
    "    print(f\"train unique values {uniqueValues_train}\")\n",
    "    print(f\"train occur count {occurCount_train}\")\n",
    "    \n",
    "    print(f\"test unique values {uniqueValues_test}\")\n",
    "    print(f\"test occur count {occurCount_test}\")\n",
    "   \n",
    "    model.save(filename+\".h5\")\n",
    "    \n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the input data for preview\n",
    "input_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting histogram of age\n",
    "\n",
    "x = input_csv['age']\n",
    "num_bins = 20\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(x, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.ylim([1000, 3000])\n",
    "# add a 'best fit' line\n",
    "#y = mlab.normpdf(bins, mu, sigma)\n",
    "\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Probability')\n",
    "plt.title(r'Histogram of Age')\n",
    "\n",
    "# Tweak spacing to prevent clipping of ylabel\n",
    "plt.subplots_adjust(left=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking into balanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_data_df = input_csv.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_data_df = stroke_data_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30468</td>\n",
       "      <td>Male</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56543</td>\n",
       "      <td>Female</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52800</td>\n",
       "      <td>Female</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>77.59</td>\n",
       "      <td>17.7</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41413</td>\n",
       "      <td>Female</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>243.53</td>\n",
       "      <td>27.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15266</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>77.67</td>\n",
       "      <td>32.3</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "1  30468    Male  58.0             1              0          Yes   \n",
       "3  56543  Female  70.0             0              0          Yes   \n",
       "6  52800  Female  52.0             0              0          Yes   \n",
       "7  41413  Female  75.0             0              1          Yes   \n",
       "8  15266  Female  32.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "1        Private          Urban              87.96  39.2     never smoked   \n",
       "3        Private          Rural              69.04  35.9  formerly smoked   \n",
       "6        Private          Urban              77.59  17.7  formerly smoked   \n",
       "7  Self-employed          Rural             243.53  27.0     never smoked   \n",
       "8        Private          Rural              77.67  32.3           smokes   \n",
       "\n",
       "   stroke  \n",
       "1       0  \n",
       "3       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29072, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolating Positive Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_positive = stroke_data_df[stroke_data_df['stroke'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30468</td>\n",
       "      <td>Male</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>87.96</td>\n",
       "      <td>39.2</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56543</td>\n",
       "      <td>Female</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>69.04</td>\n",
       "      <td>35.9</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52800</td>\n",
       "      <td>Female</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>77.59</td>\n",
       "      <td>17.7</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41413</td>\n",
       "      <td>Female</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>243.53</td>\n",
       "      <td>27.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15266</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>77.67</td>\n",
       "      <td>32.3</td>\n",
       "      <td>smokes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "1  30468    Male  58.0             1              0          Yes   \n",
       "3  56543  Female  70.0             0              0          Yes   \n",
       "6  52800  Female  52.0             0              0          Yes   \n",
       "7  41413  Female  75.0             0              1          Yes   \n",
       "8  15266  Female  32.0             0              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "1        Private          Urban              87.96  39.2     never smoked   \n",
       "3        Private          Rural              69.04  35.9  formerly smoked   \n",
       "6        Private          Urban              77.59  17.7  formerly smoked   \n",
       "7  Self-employed          Rural             243.53  27.0     never smoked   \n",
       "8        Private          Rural              77.67  32.3           smokes   \n",
       "\n",
       "   stroke  \n",
       "1       0  \n",
       "3       0  \n",
       "6       0  \n",
       "7       0  \n",
       "8       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "stroke_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28524, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_positive.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolating Negative Stroke Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_negative = stroke_data_df[stroke_data_df['stroke'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>56669</td>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "63    9046    Male  67.0             0              1          Yes   \n",
       "141  31112    Male  80.0             0              1          Yes   \n",
       "257  60182  Female  49.0             0              0          Yes   \n",
       "264   1665  Female  79.0             1              0          Yes   \n",
       "288  56669    Male  81.0             0              0          Yes   \n",
       "\n",
       "         work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "63         Private          Urban             228.69  36.6  formerly smoked   \n",
       "141        Private          Rural             105.92  32.5     never smoked   \n",
       "257        Private          Urban             171.23  34.4           smokes   \n",
       "264  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "288        Private          Urban             186.21  29.0  formerly smoked   \n",
       "\n",
       "     stroke  \n",
       "63        1  \n",
       "141       1  \n",
       "257       1  \n",
       "264       1  \n",
       "288       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(548, 12)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_negative.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Stroke Positive 28524\n",
      "Total Number of Stroke Negative 548\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Number of Stroke Positive {len(stroke_positive)}\")\n",
    "print(f\"Total Number of Stroke Negative {len(stroke_negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping String Data to Numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = {\"Other\":2,\"Male\":1, \"Female\":0}\n",
    "Married = {\"Yes\":1, \"No\":0}\n",
    "Work_Type = {\"Private\":0, \"Self-employed\":1, \"children\":2, \n",
    "             \"Govt_job\":3,\"Never_worked\":4}\n",
    "Residence = {\"Urban\":0, \"Rural\":1}\n",
    "Smoking = {\"never smoked\":0, \"formerly smoked\":1, \"smokes\":2, \"unknown\":3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never smoked       256\n",
       "formerly smoked    180\n",
       "smokes             112\n",
       "Name: smoking_status, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_negative[\"smoking_status\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_negative = stroke_negative.replace({\"gender\":Gender, \"ever_married\":Married,\n",
    "                                          \"work_type\":Work_Type, \"Residence_type\":Residence,\n",
    "                                          \"smoking_status\":Smoking})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_positive = stroke_positive.replace({\"gender\":Gender, \"ever_married\":Married,\n",
    "                                          \"work_type\":Work_Type, \"Residence_type\":Residence,\n",
    "                                          \"smoking_status\":Smoking})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9046</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>31112</td>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>60182</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1665</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>56669</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  gender   age  hypertension  heart_disease  ever_married  \\\n",
       "63    9046       1  67.0             0              1             1   \n",
       "141  31112       1  80.0             0              1             1   \n",
       "257  60182       0  49.0             0              0             1   \n",
       "264   1665       0  79.0             1              0             1   \n",
       "288  56669       1  81.0             0              0             1   \n",
       "\n",
       "     work_type  Residence_type  avg_glucose_level   bmi  smoking_status  \\\n",
       "63           0               0             228.69  36.6               1   \n",
       "141          0               1             105.92  32.5               0   \n",
       "257          0               0             171.23  34.4               2   \n",
       "264          1               1             174.12  24.0               0   \n",
       "288          0               0             186.21  29.0               1   \n",
       "\n",
       "     stroke  \n",
       "63        1  \n",
       "141       1  \n",
       "257       1  \n",
       "264       1  \n",
       "288       1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "gender                 int64\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married           int64\n",
       "work_type              int64\n",
       "Residence_type         int64\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status         int64\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stroke_negative.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating various Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data Set for Analysis - Equal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative data set 548\n",
      "Positive data set 28524\n",
      "Combined data set 29072\n",
      "Shape of combined (29072, 11)\n",
      "**********************\n",
      "Before X: (29072, 10)\n",
      "Before y: (29072,)\n",
      "**********************\n",
      "SMOTED X: (57048, 10)\n",
      "SMOTED y: (57048,)\n",
      "X_scaler: MinMaxScaler()\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 55)                605       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 55)                3080      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 2)                 112       \n",
      "=================================================================\n",
      "Total params: 13,037\n",
      "Trainable params: 13,037\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 42786 samples\n",
      "Epoch 1/100\n",
      "42786/42786 [==============================] - 3s 77us/sample - loss: 0.4222 - precision_at_recall_4: 0.7687\n",
      "Epoch 2/100\n",
      "42786/42786 [==============================] - 3s 71us/sample - loss: 0.3927 - precision_at_recall_4: 0.7978\n",
      "Epoch 3/100\n",
      "42786/42786 [==============================] - 3s 71us/sample - loss: 0.3803 - precision_at_recall_4: 0.8105\n",
      "Epoch 4/100\n",
      "42786/42786 [==============================] - 3s 64us/sample - loss: 0.3678 - precision_at_recall_4: 0.8253\n",
      "Epoch 5/100\n",
      "42786/42786 [==============================] - 3s 59us/sample - loss: 0.3548 - precision_at_recall_4: 0.8349\n",
      "Epoch 6/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.3416 - precision_at_recall_4: 0.8489\n",
      "Epoch 7/100\n",
      "42786/42786 [==============================] - 3s 62us/sample - loss: 0.3321 - precision_at_recall_4: 0.8574\n",
      "Epoch 8/100\n",
      "42786/42786 [==============================] - 3s 62us/sample - loss: 0.3256 - precision_at_recall_4: 0.8630\n",
      "Epoch 9/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.3179 - precision_at_recall_4: 0.8677\n",
      "Epoch 10/100\n",
      "42786/42786 [==============================] - 3s 60us/sample - loss: 0.3116 - precision_at_recall_4: 0.8758\n",
      "Epoch 11/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.3063 - precision_at_recall_4: 0.8792\n",
      "Epoch 12/100\n",
      "42786/42786 [==============================] - 3s 60us/sample - loss: 0.2988 - precision_at_recall_4: 0.8868\n",
      "Epoch 13/100\n",
      "42786/42786 [==============================] - 3s 60us/sample - loss: 0.2938 - precision_at_recall_4: 0.8924\n",
      "Epoch 14/100\n",
      "42786/42786 [==============================] - 2s 57us/sample - loss: 0.2892 - precision_at_recall_4: 0.8951\n",
      "Epoch 15/100\n",
      "42786/42786 [==============================] - 2s 58us/sample - loss: 0.2836 - precision_at_recall_4: 0.8997\n",
      "Epoch 16/100\n",
      "42786/42786 [==============================] - 2s 58us/sample - loss: 0.2783 - precision_at_recall_4: 0.9034\n",
      "Epoch 17/100\n",
      "42786/42786 [==============================] - 3s 60us/sample - loss: 0.2717 - precision_at_recall_4: 0.9103\n",
      "Epoch 18/100\n",
      "42786/42786 [==============================] - 2s 58us/sample - loss: 0.2693 - precision_at_recall_4: 0.9130\n",
      "Epoch 19/100\n",
      "42786/42786 [==============================] - 3s 60us/sample - loss: 0.2638 - precision_at_recall_4: 0.9176\n",
      "Epoch 20/100\n",
      "42786/42786 [==============================] - 2s 57us/sample - loss: 0.2602 - precision_at_recall_4: 0.9190\n",
      "Epoch 21/100\n",
      "42786/42786 [==============================] - 2s 56us/sample - loss: 0.2559 - precision_at_recall_4: 0.9220\n",
      "Epoch 22/100\n",
      "42786/42786 [==============================] - 3s 65us/sample - loss: 0.2519 - precision_at_recall_4: 0.9261\n",
      "Epoch 23/100\n",
      "42786/42786 [==============================] - 3s 66us/sample - loss: 0.2483 - precision_at_recall_4: 0.9288\n",
      "Epoch 24/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.2445 - precision_at_recall_4: 0.9280\n",
      "Epoch 25/100\n",
      "42786/42786 [==============================] - 3s 69us/sample - loss: 0.2397 - precision_at_recall_4: 0.93240s - loss: 0.2387 - precision_at_rec\n",
      "Epoch 26/100\n",
      "42786/42786 [==============================] - 3s 76us/sample - loss: 0.2367 - precision_at_recall_4: 0.9338\n",
      "Epoch 27/100\n",
      "42786/42786 [==============================] - 3s 63us/sample - loss: 0.2354 - precision_at_recall_4: 0.9353\n",
      "Epoch 28/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.2302 - precision_at_recall_4: 0.9385\n",
      "Epoch 29/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.2264 - precision_at_recall_4: 0.9421\n",
      "Epoch 30/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.2261 - precision_at_recall_4: 0.9425\n",
      "Epoch 31/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.2227 - precision_at_recall_4: 0.9438\n",
      "Epoch 32/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.2221 - precision_at_recall_4: 0.9437\n",
      "Epoch 33/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.2171 - precision_at_recall_4: 0.9465\n",
      "Epoch 34/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.2133 - precision_at_recall_4: 0.9480\n",
      "Epoch 35/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.2113 - precision_at_recall_4: 0.9503\n",
      "Epoch 36/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.2137 - precision_at_recall_4: 0.9488\n",
      "Epoch 37/100\n",
      "42786/42786 [==============================] - 2s 56us/sample - loss: 0.2057 - precision_at_recall_4: 0.95390s - loss: 0.2075 - precision_at_recall_4: 0\n",
      "Epoch 38/100\n",
      "42786/42786 [==============================] - ETA: 0s - loss: 0.2056 - precision_at_recall_4: 0.953 - 2s 56us/sample - loss: 0.2056 - precision_at_recall_4: 0.9534\n",
      "Epoch 39/100\n",
      "42786/42786 [==============================] - 2s 56us/sample - loss: 0.2033 - precision_at_recall_4: 0.9543\n",
      "Epoch 40/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.2015 - precision_at_recall_4: 0.9543\n",
      "Epoch 41/100\n",
      "42786/42786 [==============================] - 2s 57us/sample - loss: 0.1992 - precision_at_recall_4: 0.9558\n",
      "Epoch 42/100\n",
      "42786/42786 [==============================] - 2s 57us/sample - loss: 0.1972 - precision_at_recall_4: 0.9569\n",
      "Epoch 43/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1954 - precision_at_recall_4: 0.95730s - loss: 0.1945 - precision_\n",
      "Epoch 44/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1927 - precision_at_recall_4: 0.9591\n",
      "Epoch 45/100\n",
      "42786/42786 [==============================] - 2s 48us/sample - loss: 0.1973 - precision_at_recall_4: 0.9567\n",
      "Epoch 46/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1860 - precision_at_recall_4: 0.9625\n",
      "Epoch 47/100\n",
      "42786/42786 [==============================] - 2s 48us/sample - loss: 0.1878 - precision_at_recall_4: 0.9623\n",
      "Epoch 48/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1853 - precision_at_recall_4: 0.9624\n",
      "Epoch 49/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1833 - precision_at_recall_4: 0.9644\n",
      "Epoch 50/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1818 - precision_at_recall_4: 0.9647\n",
      "Epoch 51/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1815 - precision_at_recall_4: 0.9649\n",
      "Epoch 52/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1811 - precision_at_recall_4: 0.9651\n",
      "Epoch 53/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1784 - precision_at_recall_4: 0.9663\n",
      "Epoch 54/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1766 - precision_at_recall_4: 0.9663\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1750 - precision_at_recall_4: 0.9676\n",
      "Epoch 56/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1736 - precision_at_recall_4: 0.9678\n",
      "Epoch 57/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1738 - precision_at_recall_4: 0.9678\n",
      "Epoch 58/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.1720 - precision_at_recall_4: 0.9692\n",
      "Epoch 59/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1711 - precision_at_recall_4: 0.9687\n",
      "Epoch 60/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1693 - precision_at_recall_4: 0.96921s - loss: 0.1687\n",
      "Epoch 61/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1730 - precision_at_recall_4: 0.9681\n",
      "Epoch 62/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1667 - precision_at_recall_4: 0.97141s - loss: 0.1575 - \n",
      "Epoch 63/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1633 - precision_at_recall_4: 0.9720\n",
      "Epoch 64/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1628 - precision_at_recall_4: 0.9732\n",
      "Epoch 65/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1624 - precision_at_recall_4: 0.9725\n",
      "Epoch 66/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.1596 - precision_at_recall_4: 0.97371s - loss: 0.1542 - preci\n",
      "Epoch 67/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.1622 - precision_at_recall_4: 0.9733\n",
      "Epoch 68/100\n",
      "42786/42786 [==============================] - 3s 72us/sample - loss: 0.1589 - precision_at_recall_4: 0.9738\n",
      "Epoch 69/100\n",
      "42786/42786 [==============================] - 3s 73us/sample - loss: 0.1591 - precision_at_recall_4: 0.9742\n",
      "Epoch 70/100\n",
      "42786/42786 [==============================] - 3s 69us/sample - loss: 0.1586 - precision_at_recall_4: 0.9747\n",
      "Epoch 71/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.1562 - precision_at_recall_4: 0.9753\n",
      "Epoch 72/100\n",
      "42786/42786 [==============================] - 2s 48us/sample - loss: 0.1539 - precision_at_recall_4: 0.9749\n",
      "Epoch 73/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.1535 - precision_at_recall_4: 0.9752\n",
      "Epoch 74/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1549 - precision_at_recall_4: 0.9757\n",
      "Epoch 75/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1493 - precision_at_recall_4: 0.9782\n",
      "Epoch 76/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1509 - precision_at_recall_4: 0.9773\n",
      "Epoch 77/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1504 - precision_at_recall_4: 0.9768\n",
      "Epoch 78/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1486 - precision_at_recall_4: 0.9780\n",
      "Epoch 79/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.1493 - precision_at_recall_4: 0.9774\n",
      "Epoch 80/100\n",
      "42786/42786 [==============================] - 3s 58us/sample - loss: 0.1486 - precision_at_recall_4: 0.9771\n",
      "Epoch 81/100\n",
      "42786/42786 [==============================] - 2s 52us/sample - loss: 0.1462 - precision_at_recall_4: 0.9791\n",
      "Epoch 82/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1436 - precision_at_recall_4: 0.9795\n",
      "Epoch 83/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1418 - precision_at_recall_4: 0.9807\n",
      "Epoch 84/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1399 - precision_at_recall_4: 0.9800\n",
      "Epoch 85/100\n",
      "42786/42786 [==============================] - 2s 53us/sample - loss: 0.1433 - precision_at_recall_4: 0.9799\n",
      "Epoch 86/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1393 - precision_at_recall_4: 0.9815\n",
      "Epoch 87/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1427 - precision_at_recall_4: 0.9796\n",
      "Epoch 88/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.1366 - precision_at_recall_4: 0.98131s - loss: 0.1351 - pr\n",
      "Epoch 89/100\n",
      "42786/42786 [==============================] - 3s 61us/sample - loss: 0.1380 - precision_at_recall_4: 0.9812\n",
      "Epoch 90/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1399 - precision_at_recall_4: 0.9804\n",
      "Epoch 91/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1362 - precision_at_recall_4: 0.9816\n",
      "Epoch 92/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1364 - precision_at_recall_4: 0.9814\n",
      "Epoch 93/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1341 - precision_at_recall_4: 0.9818\n",
      "Epoch 94/100\n",
      "42786/42786 [==============================] - 2s 57us/sample - loss: 0.1381 - precision_at_recall_4: 0.9809\n",
      "Epoch 95/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1354 - precision_at_recall_4: 0.9818\n",
      "Epoch 96/100\n",
      "42786/42786 [==============================] - 2s 50us/sample - loss: 0.1338 - precision_at_recall_4: 0.9828\n",
      "Epoch 97/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1342 - precision_at_recall_4: 0.9819\n",
      "Epoch 98/100\n",
      "42786/42786 [==============================] - 2s 51us/sample - loss: 0.1327 - precision_at_recall_4: 0.9828\n",
      "Epoch 99/100\n",
      "42786/42786 [==============================] - 2s 49us/sample - loss: 0.1315 - precision_at_recall_4: 0.9833\n",
      "Epoch 100/100\n",
      "42786/42786 [==============================] - 2s 54us/sample - loss: 0.1313 - precision_at_recall_4: 0.9832\n",
      "14262/14262 - 1s - loss: 0.2702 - precision_at_recall_4: 0.9537\n",
      "/n\n",
      "Test Results\n",
      "Normal Neural Network - Loss: 0.270244914288692, Accuracy: 0.9537168145179749\n",
      "train unique values [0 1]\n",
      "train occur count [21384 21402]\n",
      "test unique values [0 1]\n",
      "test occur count [7140 7122]\n",
      "(57048, 10) (57048,)\n",
      "Total samples: 57048\n",
      "True Positive: 27060\n",
      "True Negative: 26504\n",
      "False Positive: 2020\n",
      "False Negative: 1464\n"
     ]
    }
   ],
   "source": [
    "column_headings=[\"Loss\",\"Accuracy\",\"TP\", \"TN\", \"FP\", \"FN\"]\n",
    "results_df = pd.DataFrame(columns = column_headings)\n",
    "for i in range(0,1):\n",
    "    \n",
    "    stroke_negative_sample = stroke_negative.sample(548)\n",
    "    stroke_negative_sample = stroke_negative_sample.drop(\"id\",axis = 1)\n",
    "    stroke_positive_sample = stroke_positive.sample(28524)\n",
    "    stroke_positive_sample = stroke_positive_sample.drop(\"id\",axis = 1)\n",
    "    \n",
    "    stroke_sample = pd.merge(stroke_negative_sample, stroke_positive_sample, how = 'outer')\n",
    "\n",
    "    print(f\"Negative data set {len(stroke_negative_sample)}\")\n",
    "    print(f\"Positive data set {len(stroke_positive_sample)}\")\n",
    "    print(f\"Combined data set {len(stroke_sample)}\")\n",
    "    print(f\"Shape of combined {stroke_sample.shape}\")\n",
    "\n",
    "    X = stroke_sample.drop(\"stroke\", axis = 1)\n",
    "    y = stroke_sample[\"stroke\"]\n",
    "    filename = \"NNM-SMOTE\"\n",
    "\n",
    "    model_data = neural_net(X,y, filename)\n",
    "\n",
    "    ## Loading a model to test performance\n",
    "\n",
    "    \n",
    "    # Load the model\n",
    "    from tensorflow.keras.models import load_model\n",
    "    #filename = \"NN_1B\"\n",
    "    stroke_model = load_model(filename+\".h5\")\n",
    "\n",
    "#     stroke_negative_sample = stroke_negative.sample(548)\n",
    "#     stroke_negative_sample = stroke_negative_sample.drop(\"id\", axis = 1)\n",
    "#     stroke_positive_sample = stroke_positive.sample(28524)\n",
    "#     stroke_positive_sample = stroke_positive_sample.drop(\"id\",axis = 1)\n",
    "#     stroke_sample = pd.merge(stroke_negative_sample, stroke_positive_sample, how = 'outer')\n",
    "\n",
    "#     X = stroke_sample.drop(\"stroke\", axis = 1)\n",
    "#     y = stroke_sample[\"stroke\"]\n",
    "\n",
    "    X = model_data[0]\n",
    "    y = model_data[1]\n",
    "    \n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "    X_scaler = MinMaxScaler().fit(X)\n",
    "    X_scaled = X_scaler.transform(X)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(y)\n",
    "    encoded_y = label_encoder.transform(y)\n",
    "    y_categorical = to_categorical(encoded_y)\n",
    "\n",
    "    encoded_predictions = stroke_model.predict_classes(X_scaled)\n",
    "\n",
    "    TN = 0\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    FP = 0\n",
    "    for i in range(0,len(encoded_y)):\n",
    "        if encoded_predictions[i] == 0:\n",
    "            if encoded_y[i] == 0:\n",
    "                TN += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        if encoded_predictions[i] == 1:\n",
    "            if encoded_y[i] == 1:\n",
    "                TP += 1\n",
    "            else: \n",
    "                FP += 1\n",
    "    total = FP+FN+TN+TP\n",
    "    print(f\"Total samples: {total}\")\n",
    "    print(f\"True Positive: {TP}\")\n",
    "    print(f\"True Negative: {TN}\")\n",
    "    print(f\"False Positive: {FP}\")\n",
    "    print(f\"False Negative: {FN}\")\n",
    "    \n",
    "#     result = {\"Loss\":model_perf[0], \"Accuracy\":model_perf[1], \"TP\":TP, \"TN\":TN, \"FP\":FP, \"FN\":FN}\n",
    "#     results_df = results_df.append(result, ignore_index = True)\n",
    "    \n",
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(filename+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   No Stroke       0.98      0.92      0.95     28524\n",
      "      Stroke       0.92      0.98      0.95     28524\n",
      "\n",
      "    accuracy                           0.95     57048\n",
      "   macro avg       0.95      0.95      0.95     57048\n",
      "weighted avg       0.95      0.95      0.95     57048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(encoded_y, encoded_predictions,\n",
    "                            target_names=[\"No Stroke\", \"Stroke\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stroke_negative_sample = stroke_negative.sample(50)\n",
    "stroke_negative_sample = stroke_negative_sample.drop(\"id\",axis = 1)\n",
    "stroke_positive_sample = stroke_positive.sample(200)\n",
    "stroke_positive_sample = stroke_positive_sample.drop(\"id\",axis = 1)\n",
    "\n",
    "stroke_sample = pd.merge(stroke_negative_sample, stroke_positive_sample, how = 'outer')\n",
    "\n",
    "x1 = stroke_negative_sample[\"age\"]\n",
    "y1 = stroke_negative_sample[\"avg_glucose_level\"]\n",
    "\n",
    "x2 = stroke_positive_sample[\"age\"]\n",
    "y2 = stroke_positive_sample[\"avg_glucose_level\"]\n",
    "\n",
    "c = stroke_sample[\"stroke\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = plt.scatter(x1,y1,s=50, c = \"blue\")\n",
    "positive = plt.scatter(x2,y2,s=50, c=\"red\")\n",
    "plt.legend([negative, (negative, positive)],[\"stroke\", \"no stroke\"])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Average Glucose Level\")\n",
    "plt.title(\"Stroke Data (200 No Stroke, 50 Stroke)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stroke_sample.drop(\"stroke\", axis = 1)\n",
    "y = stroke_sample[\"stroke\"]\n",
    "sm = SMOTE()\n",
    "X, y = sm.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_sample = pd.concat([X, y], axis = 1)\n",
    "x1 = smote_sample[smote_sample[\"stroke\"] == 1][\"age\"]\n",
    "y1 = smote_sample[smote_sample[\"stroke\"] == 1][\"avg_glucose_level\"]\n",
    "x2 = smote_sample[smote_sample[\"stroke\"] == 0][\"age\"]\n",
    "y2 = smote_sample[smote_sample[\"stroke\"] == 0][\"avg_glucose_level\"]\n",
    "negative = plt.scatter(x1,y1,s=50, c = \"blue\")\n",
    "positive = plt.scatter(x2,y2,s=50, c=\"red\")\n",
    "plt.legend([negative, (negative, positive)],[\"stroke\", \"no stroke\"])\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Average Glucose Level\")\n",
    "plt.title(\"Stroke Data After SMOTE (200 No Stroke, 200 Stroke)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data set of values for different training sets and layer numbers was setup for analysis.  Each was run independently and then exported as a CSV file.  These were imported into excel for basic combining.  A master CSV was generated to allow comparison of conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "nn_perf_df = pd.read_csv(\"support_docs\\master_data_NN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_perf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_perf_df[\"Layers\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_perf_df[\"Accuracy\"] = (nn_perf_df[\"Accuracy\"].str.strip(\"%\").astype(float))\n",
    "nn_perf_df[\"Precision\"] = (nn_perf_df[\"Precision\"].str.strip(\"%\").astype(float))\n",
    "nn_perf_df[\"Recall\"] = (nn_perf_df[\"Recall\"].str.strip(\"%\").astype(float))\n",
    "nn_perf_df[\"F1\"] = (nn_perf_df[\"F1\"].str.strip(\"%\").astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_perf_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_perf_df[\"Layer 1\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of Layers and Training Size\n",
    "\n",
    "from matplotlib import cm\n",
    "layers = [1,4]\n",
    "training = [548, 20000]\n",
    "\n",
    "#plot 1\n",
    "red_diamond = dict(markerfacecolor='r', marker='D')\n",
    "fig = plt.figure(figsize = (15,12))\n",
    "ax1 = fig.add_subplot(321)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Accuracy vs Number of Layers')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_ylim(-5,100)\n",
    "ax1.boxplot([nn_perf_df[\"Accuracy\"][nn_perf_df[\"Layers\"]==layers[i]] for i in range(0,len(layers))], labels=layers, showfliers = True,\n",
    "           flierprops = red_diamond)\n",
    "\n",
    "#plot 2\n",
    "ax2 = fig.add_subplot(322)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax2.set_title('Recall vs Number of Layers')\n",
    "ax2.set_ylabel('Recall')\n",
    "ax2.set_ylim(-5,100)\n",
    "\n",
    "x=[]\n",
    "y =[]\n",
    "for i in range(0,len(nn_perf_df)):\n",
    "    if nn_perf_df.iloc[i][3] == 4:\n",
    "        x.append(1.75)\n",
    "    else:\n",
    "        x.append(0.75)\n",
    "    y.append(nn_perf_df.iloc[i][27])\n",
    "ax2.scatter(x,y, c=cm.prism(x), alpha = 0.4)\n",
    "ax2.boxplot([nn_perf_df[\"Recall\"][nn_perf_df[\"Layers\"]==layers[i]] for i in range(0,len(layers))], labels=layers, showfliers = True,\n",
    "          flierprops = red_diamond)\n",
    "\n",
    "#plot 3\n",
    "ax3 = fig.add_subplot(323)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax3.set_title('Accuracy vs Training Size')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_ylim(-5,100)\n",
    "ax3.boxplot([nn_perf_df[\"Accuracy\"][nn_perf_df[\"N-Negative\"]==training[i]] for i in range(0,len(training))], labels=training, showfliers = True,\n",
    "           flierprops = red_diamond)\n",
    "\n",
    "#plot4\n",
    "ax4 = fig.add_subplot(324)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax4.set_title('Recall vs Training Size')\n",
    "ax4.set_ylabel('Recall')\n",
    "ax4.set_ylim(-5,100)\n",
    "ax4.boxplot([nn_perf_df[\"Recall\"][nn_perf_df[\"N-Negative\"]==training[i]] for i in range(0,len(training))], labels=training, showfliers = True,\n",
    "           flierprops = red_diamond)\n",
    "\n",
    "#plot5\n",
    "x=[]\n",
    "y =[]\n",
    "for i in range(0,len(nn_perf_df)):\n",
    "    if nn_perf_df.iloc[i][0] == 20000:\n",
    "        x.append(1.75)\n",
    "    else:\n",
    "        x.append(0.75)\n",
    "    y.append(nn_perf_df.iloc[i][26])\n",
    "    \n",
    "ax4 = fig.add_subplot(325)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax4.set_title('Precision vs Training Size')\n",
    "ax4.set_ylabel('Precision')\n",
    "ax4.set_ylim(-5,100)\n",
    "ax4.boxplot([nn_perf_df[\"Precision\"][nn_perf_df[\"N-Negative\"]==training[i]] for i in range(0,len(training))], labels=training, showfliers = True,\n",
    "           flierprops = red_diamond)\n",
    "ax4.scatter(x,y, c=cm.prism(x), alpha = 0.4)\n",
    "\n",
    "#plot6\n",
    "ax4 = fig.add_subplot(326)\n",
    "#fig1, ax1 = plt.subplots()\n",
    "ax4.set_title('F1 vs Training Size')\n",
    "ax4.set_ylabel('F1')\n",
    "ax4.set_ylim(-5,100)\n",
    "ax4.boxplot([nn_perf_df[\"F1\"][nn_perf_df[\"N-Negative\"]==training[i]] for i in range(0,len(training))], labels=training, showfliers = True,\n",
    "           flierprops = red_diamond)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
