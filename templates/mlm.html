<!DOCTYPE html>
<html lang="en">

<head>


    <meta charset="utf-8">
    <!-- Bootstrap -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css"
        integrity="sha384-TX8t27EcRE3e/ihU7zmQxVncDAy5uIKz4rEkgIXeMed4M0jlfIDPvg6uqKI2xXr2" crossorigin="anonymous">

    <!-- Title of Home Page -->
    <title>Stroke Prediction: Machine Learning Models</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="../static/css/style.css">

</head>

<body>

    <!-- nav bar -->
    <div class="container-fluid">
        <nav class="navbar navbar-expand-lg navbar-light bg-light">

            <a class="navbar-brand" href="/">Stroke Prediction</a>

            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNavDropdown"
                aria-controls="navbarNavDropdown" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <ul class="navbar-nav">
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarDropdownMenuLink" role="button"
                        data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                        Info
                    </a>
                    <div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">

                        <a class="dropdown-item" href="/charts">Charts</a>
                        <a class="dropdown-item" href="/mlm">Machine Learning</a>
                        <a class="dropdown-item" href="/resources">Resources</a>
                        <a class="dropdown-item" href="/about">About Us</a>
                    </div>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="/strokePredictor">Stroke Predictor</a>

                </li>
            </ul>
        </nav>
    </div>

     <!-- first container -->
     <div class="container">
        <!-- row #1 -->
        <div class="row">
            <!-- col 1 through 3 -->
            <div class="col-lg-2">
            </div>
            <!-- col 4 through 9 -->
            <div class="col-lg-8">
                <br><br>

                <h1>
                    <center>Machine Learning Models for Predicting Risk of Stroke</center>
                </h1>
                <br>
                <br>
                <p> Researchers have made available a dataset which provides an individuals health information and 
                    whether or not the individual had suffered a stroke.  The data set can be found at: <br>

                    <p style = "font-size: small">Liu, Tianyu; Fan, Wenhui; Wu, Cheng (2019), “Data for: A hybrid machine learning approach to cerebral 
                    stroke prediction based on imbalanced medical-datasets”, Mendeley Data, V1, doi: 10.17632/x8ygrw87jw.1 </p>
                    <br>
                    The data set contains the following information on the individuals:<br><br>

                    <ul>
                        <li>Gender</li>
                        <li>Age</li>
                        <li>Hypertension (Y/N)</li>
                        <li>Heart Disease (Y/N)</li>
                        <li>Marital Status</li>
                        <li>Work Status</li>
                        <li>Residence Type (Urban/Rural)</li>
                        <li>Glucose Level</li>
                        <li>BMI</li>
                        <li>Smoking Status</li>
                    </ul>

                    Using this data is it possible to create a model that predicts ones risk of stroke-symptoms?  Several machine
                    learning models were used in an attempt to find a suitable solution: <br><br>

                    <ul>
                        <li>Decision Tree</li>
                        <li>Random Forest</li>
                        <li>Logistic Regression</li>
                        <li>k Nearest Neighbor (KNN)</li>
                        <li>Neural Network</li>
                    </ul>

                    Initially all models failed to find an acceptable model based on three metrics:
                <div class="row">
                    <!-- <div class="col-lg-2"></div> -->
                   <div class = "row_img">
                        <div class="col-lg-8">
                            <center>
                                <br>
                                <img class="img-responsive" style="width: auto; height: 35px" src = "/static/images/precision.png" alt = "precision_def"/>
                                <p style = "font-size: small"> Precision is ratio of correctly predicted results to the total predicted positive observations</p>
                                <img class="img-responsive" style="width: auto; height: 30px" src = "/static/images/recall.png" alt = "recall_def"/>
                                <p style = "font-size: small"> Recall is ratio of correctly predicted results to the total positive predicted cases</p>
                                <img class="img-responsive" style="width: auto; height: 40px" src = "/static/images/f1.png" alt = "f1_def"  />
                              
                                <p style = "font-size: small"> F1 is the harmonic average of the precision and recall</p>
                                <br>
                                <p>Where TP = True Positive; FP = False Positive; FN = False Negatives. </p>
                            </center>
                        </div>
                    </div>
                </div>
                 
                    <br><br>

                    <p>Why were the machine models not able to give good results?  Reviewing the data showed the data was highly imbalanced.  The number
                        of people who had strokes in the dataset was 548.  The number who did not have stroke was 28,524.  Therefore the data set was strongly
                        skewed to people who did not have strokes.  This affects the metrics for the model. As an example assume a model has an accuracy of 95% for both
                        people with stroke and people without stroke.  This is a good result.  If we fix the population size for non-stroke at 20,000 and vary the 
                        number of people who had stroke, how would this affect the precision and recall?  This is shown in the Figure below.
                    </p>
               <figure class = "figure">
                   <img src = "\static\images\precision_recall_model.png" class="figure-img img-fluid rounded" alt = "effect of positive counts on precision and recall">
                  <center> <figcaption class = "figure-caption">Effect of positive counts on recall and precision</figcaption>
                  </center>
                </figure>
                    <p>The analysis shown in the plot uses a fixed negative stroke count of 20,000.  The positive stroke count is varied in the calculation.  While
                        the recall remains constant, the precision is seen to decrease as positive stroke count decreases.  This is because even though the accuracy is 95% the 
                        number of false positives is high (5% of 20,000 or 1000 counts) relative to the the lower counts of positive strokes (as an example for 500 positive strokes
                        5% is 25 false negatives which gives a precision of 25/1025 = 24%). Therefore an alternative approach is required in order to properly analyze imbalanced data.
                    </p>
                    <br><br>
                    <h2>Enter SMOTE</h2>
                    <p>In an imbalanced classification data set there is generally too few examples in the smaller population for a model to effectively learn the boundary between pass and fails.
                        A solution to this problem is to oversample the data points in the minority class.  The most widely adopted method for doing this is the Synthetic Minority Oversampling Technique,
                        commonly referred to as SMOTE.  This approach was documented by Chawla in the 2002 paper:

                        <p style = "font-size: small"> Chawla et al, "SMOTE: Synthetic Minority Over-sampling Technique"; Journal of AI Research, 16, 321, 2002</p>
                        
                        In simple terms, SMOTE selects examples that are close in the feature space, drawing a line between them and drawing a new sample at a point along 
                        the line.  A good question is "does this process not change the data?".  The approach is effective because the points generated are based on the known data points.  Therefore the 
                        generated data is plausible.  <br><br>

                        As an example, a sample of data was taken from the stroke data set: 200 examples of no stroke and 50 examples of stroke.  The participants age and average glucose level are 
                        plotted in the figure below.  Individual who suffered a stroke are shown in red and those who had not suffered a stroke are shown in blue. Also shown for comparison is an example from 
                        the same data set but the data for those who suffered stroke has been over-sampled using a SMOTE technique from the imblearn python module.</p>
                <center>
                <figure class = "figure">
                    <img src = "\static\images\data_before_smote.png" class="figure-img img-fluid rounded" alt = "data distribution before oversampling">
                    <center> <figcaption class = "figure-caption">Glucose Level vs Age for 200 People Without Stroke and 50 Who Suffered from a Stroke</figcaption>
                    </center>
                </figure>

                <br>
                <figure class = "figure">
                    <img src = "\static\images\data_after_smote.png" class="figure-img img-fluid rounded" alt = "data distribution before oversampling">
                    <center> <figcaption class = "figure-caption">Glucose Level vs Age for Same Data Set After Oversampling Data from Positive Stroke</figcaption>
                    </center>
                </figure>
                </center>
                <p> As can be seen by comparing the plots the oversampling populated the positive stroke data with points 
                    contained within the limits of the existing points but randomly distributed.</p>
                <p> Several models were run using both the data set as supplied (incomplete data elements removed) and after 
                    oversampling using a SMOTE technique.  For each of these the metrics of accuracy, precision
                    recall, and F1 were calculated to evaluate model performance.  The results are shown below:</p>
                <div class="row">
                    <div class = "data_table">
                        <div class="col-lg-12">
                            <table class = "table table-bordered table-responsive table-condensed", style = "width 100%">
                                <caption style = "font-size: small"><center>Comparing Results Without and With OverSampling</center></caption>
                                <center>
                                <thead>
                                <tr>
                                    <th> Data Set </th>
                                    <th> Machine Learn Model </th>
                                    <th> Accuracy </th>
                                    <th> Precision </th>
                                    <th> Recall </th>
                                    <th> F1 </th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    
                                    <td>Imbalanced</td>
                                    <td>Random Forest</td>
                                    <td>100%</td>
                                    <td>100%</td>
                                    <td>75%</td>
                                    <td>86%</td>
                                    
                                </tr>
                                <tr>
                                    
                                    <td>Imbalanced</td>
                                    <td>Neural Network</td>
                                    <td>98%</td>
                                    <td>74%</td>
                                    <td>12%</td>
                                    <td>20%</td>
                                    
                                </tr>
                                <tr>
                                    <td>Imbalanced</td>
                                    <td>KNN</td>
                                    <td>98%</td>
                                    <td>58%</td>
                                    <td>1%</td>
                                    <td>2%</td>
                                </tr>
                                <tr>
                                    <td>Balanced (SMOTE)</td>
                                    <td>Random Forest</td>
                                    <td>99%</td>
                                    <td>99%</td>
                                    <td>100%</td>
                                    <td>99%</td>
                                </tr>
                                <tr>
                                    <td>Balanced (SMOTE)</td>
                                    <td>Neural Network</td>
                                    <td>95%</td>
                                    <td>92%</td>
                                    <td>98%</td>
                                    <td>95%</td>
                                </tr>
                                <tr>
                                    <td>Balanced (SMOTE)</td>
                                    <td>KNN</td>
                                    <td>93%</td>
                                    <td>88%</td>
                                    <td>99%</td>
                                    <td>93%</td>
                                </tr>
                            </tbody>
                            </center>
                            </table>
                        </div>
                    </div>
                </div>

                <div class="row">
                <!-- col 1 through 3 -->
                    <!-- <div class="col-lg-0"></div> -->
                    <!-- col 4 through 9 -->
                        <div class="col-lg-12">
                            <br>
                            <p> This data set shows the clear benefit of using a balanced data set.  It allows the performance of the models to be more accurately evaluated.  Several direct observations 
                                can be made from the above data:</p>
                                <ul>
                                    <li>For Imbalanced data all models shown perform poorly, albeit differently.  The data is consistently skewed due to the False Positive Results driven from the larger
                                        sample size of the no-stroke data set.
                                    </li>
                                    <li>By balancing the data both models perform very well across all metrics.
                                    </li>
                                    <li>Surprisingly the accuracy is higher for the Imbalanced data.  This shows how accuracy on its own is a misleading metric.  The result
                                        is skewed because of the imbalanced data.  Essentially the models with imbalanced data do well predicting someone will not have a stroke.  This gives a high accuracy because
                                        the data is so strongly skewed towards no-stroke conditions.
                                    </li>
                                </ul>
                             <p> Using these models we can predict if one is at increased risk for stroke.  Go to the Stroke Predictor Page (link below), enter your information and the selected model will predict your risk of stroke.</p>
                             
                            <center></center><a class="nav-link" href="/strokePredictor">Stroke Predictor</a><center></center>
                                     

                        </div>
                    
                </div>
                <br>

            </div>
            

            <row>
                <!-- add some references here if we want to. -->
            </row>

            <!-- col 10 through 12 -->
            <div class="col-lg-2">
            </div>
        </div>

    </div>





    <!-- Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-ho+j7jyWK8fNQe+A12Hb8AhRq26LrZ/JpcUGGOn+Y7RsweNrtN/tE3MoK7ZeZDyx"
        crossorigin="anonymous"></script>

    <!-- JavaScript -->
    <script type="text/javascript" src="../static/js/app.js"></script>



</body>

<footer class="footer mt-auto py-3">
    <!-- <div class="container">
      <span class="text-muted"><p><center>Team 5
          University of Minnesota Boot Camp 2020
      </center></p></span> -->
    </div>
</footer>


</html>